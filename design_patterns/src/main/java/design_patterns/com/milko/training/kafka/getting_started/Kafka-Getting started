There are some important points about Kafka consumers that I want to teach you at this point. We just covered the basics of creating a list of topics we want a single consumer to subscribe to. It's as simple as calling the subscribe method, and passing it a list. By calling this method, you are asking for automatic or dynamic partition assignment. That is to say that you're enlisting the single consumer instance to eventually pull from every partition within that topic, which can be at least one, but likely many. When adding multiple topics to the list, you're enlisting the consumer instance to pull from every partition within every topic, which is guaranteed to be many. This has very important implications which shouldn't be taken lightly for reasons we'll cover shortly. Besides subscribing to topics, there's another option: subscribing to individual partitions. This is done through the assign method. The assign method is only valid for subscribing to a list containing the class topic partition, as we'll see next, but first, let me explain a key difference between subscribe and assign methods. There is a reason why the API designers decided to call this operation out as a separate method as opposed to overloading the subscribe method. By asking for specific partitions, you're basically taking on the responsibility of assigning yourself specific partitions. More specifically, assigning specific partitions to a single consumer instance. Once you've assigned yourself a list of partitions, the consumer will then start pulling the individual partitions, regardless of the topic those partitions are part of. Both have one thing in common, they take lists, and they cannot be added to incrementally, as we covered earlier. As we'll cover later with consumer groups, this assignment responsibility is generally managed for you and for a good reason. I suppose you can say using the assign method is an advanced case, and therefore needs to be treated with respect for reasons we'll discuss later. To manually assign partitions to a Kafka consumer, you will first need to create a list containing your manual partition assignments. This is done by instantiating topic partition classes with the appropriate information. You'll see the topic partition class referenced in a lot of places in the Kafka API. It simply provides a type safe data structure to represent individual partitions within a topic. Second, you're going to invoke the assign method, passing it the list of topic partitions just created. That's about it. I'm sure you'll notice the general similarities with the subscribe method.
Single Consumer Subscriptions and Assignments

This is a good time to teach you about how individual Kafka consumer instances interact with their subscribed topics. When a single consumer subscribes to a topic using the subscribe method, it will constantly pull any and all partitions within the topic for new messages to consume. This is the case for all of the topics for which the consumer is subscribed. Depending on the number of topics, and the number of partitions within each of those topics, that could be a lot of message pulling by a single consumer. We will discuss the challenges of this approach soon, but I wanted to teach you how this works first. The benefit to using the subscribe method to retrieve data is that partition management is entirely managed for you. For example, suppose there is a new partition added to an existing topic, presumably because the administrators wanted to increase the scalability of the topic. When that happens, the metadata about the cluster will have changed, and it will be sent to the consumer. Since the consumer maintains an internal object that manages its subscriptions called subscription state, it will know if the change has affected its subscriptions. In this case, it has. So what we'll know to automatically add the new partition to the topic list, which the consumer will start polling for messages. We'll cover how this happens towards the end of this module. Pretty convenient isn't it? Just remember this capability is only available through the subscribe method. In slight contrast, a single consumer instance may want complete control over what partitions it wants to pull messages from. There are legitimate reasons this may be called for, but they are advanced use cases that we won't have a lot of time to cover in this course. By specifying a list of topic partition objects, the consumer is assigning itself to specific partitions. This is a lot like hardcoding a list of specific partition IDs in a watch list. At this point, the fact that a partition participates as part of a topic is less relevant, because as far as the consumer is concerned, it doesn't know or really care. It knows what topic each partition is in, but it doesn't really do anything with that information once it has assigned itself a partition. So if a partition is added to a topic, the consumer instance may be notified of it as per the protocol of retrieving metadata from the cluster, but it doesn't really care, and why would it? If it had good reason to assign itself specific partitions, why would it care what happens in the topic? If it was interested in what happens at the topic level, it would've used the subscribe method instead.
The Poll Loop

We've talked about subscribing to topics and assigning partitions, which is really important to understand how the Kafka consumer works. You may have noticed that several times in that discourse, I used the term poll or polling. This was intentional, because now it is the time to understand what polling means within the consumer context. It would be natural to think that by invoking the subscribe or assign methods that we just talked about, you would be actually kicking off the consumer to start receiving messages. That's not how it works. Nothing happens until you start the most critical process in the entire consumer component, which is the poll loop. The poll loop is the heart and soul of the Kafka consumer, and it is what enables the consumer to realize its purpose, and that is to continuously and reliably pull the brokers and the cluster for messages. It's a single and simple method, but don't let that fool you. From that simple method, all of the complex interactions between the consumer and the broker are kicked off and coordinated. We'll get to the details of this soon, but you will see how it goes way beyond just receiving messages. Let's take a look how to start a polling process. First of all, the poll loop can't be a loop without a loop to run it in. As funny as that sounds, it's true. A Kafka consumer is a long-running application, or at least it should be, whose job is to always be looking for new messages, and process them from the Kafka cluster. There should be very few reasons you would stop polling once you've started. So think of the loop as an infinite loop that we will only be interrupting for valid reasons, whether intentional or unintentional. You start the loop by calling the poll method on the Kafka consumer object, passing it a long typed number, representing a very important value that we'll cover shortly. You'll notice the direct output of the poll method is to return an object of type ConsumerRecords, which contains any records the consumer was able to retrieve from the broker. From there, what you do with the consumer records is entirely up to you, and this is where the diversity of Kafka consumer applications come in. Otherwise, they're fairly generic as far as what it takes to get it polling for messages, you'll notice that I enclosed the call to poll within a try block. Since the Kafka consumer is idle until the poll method is invoked, there really isn't anything that can throw a runtime exception to be handled, but because the invocation of the poll method starts any and all network activity with the cluster, it is a good idea to enclose it with the means to do structured exception handling. As the poll operation opens network resources, it is always a good idea to make sure it closes in the end.
Demo: Simple Kafka Consumer

Let's go through a demo of a custom consumer application written in Java. The development environment will be the same as before. The only difference is that we'll have a consumer app class to run the consumer console application. The demo cluster configuration will consist of a single broker with two topics, each with three partitions. We'll only do a single replication factor for this demo. Look for the use of the handy kafka-producer-perf-test shell program to generate messages. Even though we're not planning on blasting our Kafka environment for performance tests, I want to use this as an opportunity to show you how to use this tool. We'll demonstrate two different consumers; one using the subscribe method for retrieving messages, and the other using assign. We'll observe the output from each consumer, and note the differences, and then we'll add a new partition to a topic. With this configuration, we'll look at the output of both consumers. You'll notice the differences between the assign consumer, and the subscribe consumer. I've already started a single Kafka broker and created two topics with three partitions each, and you can see this with the results of issuing a describe command against the cluster. Here's the Topic: my-other-topic, again, PartitionCount of three, single ReplicationFactor, and there they are with their leaders, and then we have the second topic, my-topic, with the same configuration. Before we do anything, let's take a look at our sample Kafka consumer Java applications that we've got so far. So let's open up our ID here. We have two applications actually. We have one for subscribing to topics, and the other for getting specific partitions assigned to it. As we go through this, you'll notice that our code is aligned with what we've covered in the slides up to this point. For example, here we've established the required properties for the consumer, and passed them into an instance of the Kafka consumer class, thus creating myConsumer object. And here, for the subscribe consumer, we need to create a list of topics that we're interested in watching. These topics are simply my-topic, and my-other-topic, as you saw in the terminal, and to add these topics to the consumer, we simply invoke the subscribe method here, passing in the list of topics. Next is where the action happens, starting responsibly with the try block, and setting up a loop for which we can enter into the consumer poll loop. Here you'll see that the poll method has been set with a timeout value of 10 ms, and we'll get back to what this parameter means shortly. And within this loop, we're going to be taking each record that we get from the poll method, and we're going to be iterating over it and processing it minimally. In this case, we're just taking the values that are present, and formatting them and outputting them to the console. And finally, you'll see that we literally have a finally block so that when it exits, we can responsibly close the consumer and free up the resources we need to. The assigned consumer is virtually identical. The only difference is how we construct a list of specific topics that we want to assign to our particular consumer, and here you'll see those. We have to create specific topic partition objects, one representing each of the specific partitions within a specific topic that we want to assign. Here we are going to have two. We're going to have the first partition, partition 0 from the myTopicParition, excuse me, my-topic topic, and we will have an other representing the second partition, or I should say, the third partition from my-other-topic, and we will be adding them to our list of partitions, and instead of calling the subscribe method, obviously we're invoking the assign method, and passing in that list of partitions. Everything else, as far as how we're going to be processing the records that are retrieved from those partitions, is identical. Let's go ahead and run these two consumer programs so that they can be listening for messages to arrive in their respective subscriptions or assignments, and then after that, we'll start producing some messages. So let's start with the subscribe app, all we have to do is go in here and hit run, and we'll do the same thing for the consumer app. Jumping back out to a terminal, I wanted to show you a handy tool for creating lots of messages. It's called the Kafka Producer Perf Test shell program, and this is roughly how you get it to work. So, as it says, this tool is used to verify the producer performance, so you can really just pump a bunch of messages in here, and in order to get it to work, you have to pass in a topic, you give it the number of records that you want it to produce, the size of those records, and you can also determine what the throughput you want it to be, so in this case, you'd be setting a value to represent how many messages per second. And finally, you would be passing to it a list of properties. Now, at the bare minimum, it would be the minimum required property, such as bootstrap servers, and then the, in this case, since we're producing it, would be the key serializer and the value serializer classes. So, if I have this other window up here, it's a little busy, so you can see that I'm ready to start sending some messages to here to my other topic. I've said that I want to send 50 records with just one byte each, so very small, with a throughput of 10 per second. You can't see that, it's a little cut off, but it's going to be 10 per second, so it will take a total of 5 seconds to send all of these messages, and of course I passed in the required properties, the bootstrap servers, and the string key value serializers. I'm also doing this for the other topics, so both topics will have the same configuration. Let's run our producers. Let's start off with the test producer for my-topic, and we'll run the test producer for my-other-topic. And here you're going to see a bunch of stuff getting output to the subscriber app, and if we go over here, we'll see a lot of output to the consumer app. So let's look at the results here, and then I want you to look for certain things. So, when we ran the first performance tool, you'll notice that on the subscribe app, you'll remember now that it's subscribing to all partitions by topic, so within this, you'll see for my-topic it has a mix of messages it's getting from all partitions, and then we ran the other perf tool that started publishing messages to the other topic, and just even with this, you'll start to see that it was looking at all of the partitions within that topic, as you would expect. Now the output is just based upon different producers formatting the results differently based upon what values were in the messages. Now if we go over here to KafkaConsumer where the assign method was used, we'll see some different results. For my-topic, all we see is partition 0 because if you remember, that's all we told this consumer to look for for that topic. In addition, if we see my-other-topic, which was the other topic whose partition number 2 we assigned to the consumer, that's all that it would notice. So it's doing exactly what we would expect. Now, we're going to keep this open, just as is, we're not going to stop it at all, and what I'm going to do is go over to another terminal window, and I'm going to create another partition within one of those topics, and we're going to see what happens when we start producing data to that new partition. Here in this terminal window, you'll notice that I'm using the kafka-topics-sh program, and we've seen this in action before, there's a little bit of a difference here. Yes, I'm passing in the Zookeeper reference, but here I'm using the command to alter, because I'm basically saying I want to alter this topic, which is just the my-topic topic, and I'm saying I want it to have four partitions instead of three. So let's run this, and as you can see, it says adding partitions succeeded. Now let's go into here real quick and look at our describe just to make sure that it took. Basically what you're going to see now despite all of that whizzing by, we'll get to that later, is basically you'll see that for my-topic we now have a partition count of 4, so 0-3. So, with that, go back to our producer test tools, and let's produce a new round of messages and see what happens in our consumers. So if we go back here to our applications, we're more or less left off where we had them, and that is the subscribe app and the consumer app, they're just waiting for new messages. Now remember, we added a new partition to the topic, my-topic. So in this window, we are going to create more messages that go to my-topic. We don't need to add more messages to the other topics since that was not changed, so let's do that here. So we're producing more messages to the Kafka consumer subscribe app, and as you can see, it went through, and here within the my-topic, we have now an extra partitions worth of messages that its looking at. It has 0, 1, 2, and 3, and it successfully subscribed to all of those new partitions, it became aware that there was a new partition, it added it to its subscription, and then actively started listening for it without really any intervention on our part, other than just creating the new topic. Now, let's compare that to the consumer assign app. Nothing happened. When it got more messages, it definitely received them, but it only got the messages for partition 0. You'll notice there is nothing there from partition 1, nothing there for partition 2 or 3, all it knows or cares about is partition 0. It has no knowledge that there is other partitions other than this. So that hopefully illustrates the differences a bit between the assign and the subscribe methods when polling for messages in a consumer.
Walkthrough: Consumer Polling

When the subscriber assign method is invoked, the content of the collections they were passed to are used to set fields within the subscription state object. This object serves as the source of truth for any and all details related to the topics and partitions this consumer instance is subscribed or assigned to. A lot of what happens within the consumer invariably crosses paths with this object. This object also plays a very important role with the consumer coordinator in managing the offsets, a topic we covered briefly in module three, and we'll spend a bit more time on it later in the module. When poll is invoked, consumer settings, particularly those referring to the bootstrap servers, is used to request the metadata about the cluster. This kicks off everything within the consumer. The Fetcher servers as the responsible object for most of the communication between the consumer and the cluster. Within it, there are several fetch-related operations that are executed to initiate communication with the cluster, but the Fetcher itself doesn't actually communicate with the cluster, that is the job of the Consumer Network Client. With the client open and sending TCP packets, the consumer starts sending heartbeats, which enable the cluster to know what consumers are still connected. Additionally, the initial request for metadata is sent and received. The response is used to instantiate its internal metadata object, which will keep up to date while the poll method runs, getting periodic updates from the cluster, when cluster details change. With metadata available, other major elements become more involved. With information about the cluster, the consumer coordinator can now take responsibility to coordinate between the consumer. This object has two main duties. First, being aware of automatic or dynamic partition reassignment, and notification of assignment changes to the subscription state object. And second, for committing offsets to the cluster, the confirmation of which will cause the update of the subscription state, so it can always be aware of the status of topics and partitions. To actually start retrieving messages, the Fetcher needs to know what topics or individual partitions it should be asking for. It gets this information from the subscription state object, and with it, starts requesting messages. Here is where I'll explain what that value that is being passed to the poll method means. It is a timeout setting, representing the number of milliseconds the network client is to spend polling the cluster for messages before returning. This is an important setting, because it establishes the minimum amount of time each message retrieval cycle will take. I'll cover this shortly. When the timeout expires, a batch of records are returned, and added to an in-memory buffer where they are parsed, deserialized, and grouped into consumer records by topic and partition. Once the Fetcher finishes this process, it returns the objects for processing.
Walkthrough: Message Processing

An important thing to understand about Kafka consumers is that they are essentially single-threaded. There is one poll loop per Kafka consumer, and you can only have a single thread per Kafka consumer. With all of the responsibilities that stem from the poll method, this may be surprising to you, if not downright troubling. The Kafka consumer was designed this way mainly to keep its operation simple, and to force parallelism of message consumption in another more scalable way that we'll see shortly. Again, knowing this is important for you and your approach to designing Kafka consumer applications, because the reality of only a single thread available for record processing will have implications on how much you can reasonably expect a single Kafka consumer to do. Let's discuss this further. Let's continue our walkthrough of the consumer internals by discussing what happens after the poll method is returned messages for processing. Since the return type of the poll method is a collection of consumer records, we will need to iterate through them to process them individually. Now, what logic to apply to each individual record is entirely up to the developers working on the consumers, but careful consideration should be made to how each record should be processed. Remember, when calling the poll method, you can only do so much within a single thread. If you were to spend too much time in processing records, it could have big implications on the environment in which the consumer application process is running. Thankfully, because of Kafka's architecture, a slow consumer doesn't have an impact on the cluster, producers, or other consumers. Nonetheless, it's important to remember that any one consumer can subscribe to any number of topics and partitions. The more the consumer signs up for, the more it has to process and all within a single polling loop. Given the possible load that a Kafka cluster can be required to handle, having a single consumer may not be a feasible or rational idea. Let's get into some more details about the consumer so we can explore options for developing and configuring consumer applications at scale.
The Consumer OFfset in Detail

It's been a few modules since we discussed the all-important offset. If you recall, the offset is the critical value that enables consumers to operate independently by representing the last read position the consumer has read from a partition within a topic. When you think about the business of consuming messages, you realize just how important the offset is, and more importantly, whether it is accurate. How Kafka manages the consumer offset is one of the more important things to understand, and that's why we're going to spend a bit of time on it right now. First, there is some important terminology to learn about the offset. There are different categories of offsets, with each representing the various stage they are in. When an individual is reading from a partition, it obviously needs to establish what it has and hasn't read. This definitive answer is called the last committed offset, and it represents the last record that the consumer has confirmed to have processed. We'll get into this confirmation process shortly, but this is the starting point for a consumer within any given partition, depending on the configured offset reset behavior, which we'll also cover later. You will notice we're really looking at it from a partition viewpoint, and that is because each partition is mutually exclusive with regard to consumer offsets. So, for any given topic, a consumer may have multiple offsets it's tracking; one for each partition within a topic. As the consumer reads records from the last committed offset, it tracks its current position. As we illustrated in module three, this position advances as the consumer advances in the log towards the last record in the partition, which is known as the log and offset. There is a notable difference, however, between the current position and the last committed offset, and it represents potentially uncommitted offsets. The success of robust and scalable message consumption in Apache Kafka largely depends on your understanding of what creates this gap and what can be done to narrow it. Every application has different processing requirements, functional and non-functional. It is the job of the application designer and developer to find the appropriate tradeoffs that work. Next, I will walk through a scenario that illustrates this gap. There are two very important configuration properties that govern the default behavior of the consumer offset. These properties are optional because their defaults are sufficient for getting up and running. The first is enable. auto. commit, which is basically giving Kafka the responsibility to manage when current position offsets are upgraded to full committed offsets. This is a fairly blind setting because Kafka isn't going to know under what logical circumstances a record should be considered a committed record. The only thing it can do is establish an interval of time between commit actions that faithfully commit based on a frequency. That frequency is established by the auto. commit. interval property, and by default it is set to 5000 ms or 5 seconds. Now, for high throughput scenarios, 5 seconds is an eternity, and likely sufficient, but let's consider the biggest variable here for a moment, and that is your processing logic. When a record is in processing scope, let's say it has a current offset position of four because the last successfully committed record was three. Let's also suppose that for whatever reason, the processing of the current record takes longer than 5000 ms or whatever that interval is set to. Faithfully, Kafka is going to commit that record's offset, regardless if it is finished processing or not, because unless if you tell it explicitly when it's done, how is it supposed to know? Now, this may be fine, but it's not entirely consistent. Generally large-scale systems operate within eventually consistent boundaries. Now, that's okay most of the time, provided there's something else that's very important present, and that is reliability. Sorry, but I have to stand on my little soapbox for a minute. The gap between what is considered committed and what is actually committed isn't entirely bad. As I said, many large-scale distributed systems aren't 100% consistent. They are eventually consistent, and Kafka consumers don't have to be an exception to that, but the extent in which you can tolerate eventual consistency is based on your applications functional requirements of course, but also on the degree in which you can ensure reliability. If you can't provide reliability and robustness assurances, then an eventually consistent ideal becomes a never consistent reality, which can be a disaster. So to continue with the offset gap illustration. Suppose an error occurs that causes the message processing to fail for whatever reason. Now what? Depending on how far behind the consumer was when it failed, it may be very hard to know where you may need to go back to to start processing again, because according to Kafka, the records were committed. Knowing the current position at the time will be a start, but it could be messy to recover from. The impact varies largely based on your consumer topology. So far, we've only discussed a single consumer. The issues for a single consumer are different for a topology where multiple consumers exist within what is called a consumer group. I keep pushing this down, but we'll talk about this soon enough.
Offset Behavior and Management

So to recap and summarize for now on offset behavior. Remember, just because something is read doesn't mean it's committed. A lot of things determine this, and it is very subjective depending on the offset management mode you're operating in. The offset management mode is determined by the offset configuration properties. First and foremost is whether you want Kafka to manage your commits for you. The default is true, because it is very convenient from a development standpoint, but as we saw, depending on the situation, it can be operationally inconvenient if there's an issue. It's a lot like garbage collection in modern programming languages. It's very convenient until it is inconvenient. The challenge is generally to have some sort of control to govern when it is tolerable to be inconvenient. Fortunately in Kafka, you can adjust the commit frequency to be in line with your particular consumer application. This is the commit interval we discussed earlier. Lengthening this interval will provide an upper bound in which you can ensure your record processing will be finished, but it could also create an offset gap in the opposite direction, where the commits are lagging behind your processing positions. As long as there is a gap, there is some risk exposure to failure, and the possible inconsistent state you may be left with to clean up. Not to mention the possible duplication of records when reprocessing. Another property we haven't covered yet but will is the strategy to use when a consumer starts reading from a new partition. The default is to start reading from the latest known committed offset. In contrast, this could also be set to the earliest. There's also a setting for none, which basically you're asking Kafka to throw an exception to the consumer and let you decide what to do with it. The offset behavior and the issues related to it vary depending on whether you're in a single consumer or a consumer group topology. All this time we've been talking about offsets and I haven't taught you how and where they are stored in Kafka. The only thing I've said at this point is that consumers track the offset in terms of what it has or has not read, but where does it actually store them? Any guesses? Think about how Kafka stores data period. If you guessed a topic, you would win a prize. Kafka stores the committed offsets in a special topic called __consumer_offsets. If you were to issue a describe command to the cluster asking it to show you all of the topics and their partitions, you would notice this consumer offsets topic, and it would have 50 partitions. Yeah, that's a lot of partitions for a single topic. Now why they chose the default of 50 is beyond me, but that's what it is. Using the demo from the last time where we already have a couple of topics in place and some data in them, I wanted to show you how to take a look at the __consumer_offsets topic, which again, is the designated topic to store all of the consumer offsets throughout the entire Kafka cluster. Now, in this scenario, I only have one single broker running, but let's take a look at what this offset describe would do. So here you're going to see it listing all of the partitions that are in this particular topic, which again is __consumer_offsets. It has a partition count of 50, and it only has a single replication factor, which is a little bit dangerous, but if we try to set that higher at this point with only one broker running, we would get an error. So it's probably only doing a replication factor based on the number of nodes available to it at this point by default. So we now know the committed offsets are stored in a topic on the cluster, but how does the committed offset values get produced into the topic? Remember the class consumer coordinator we touched upon earlier? This is the responsible object for communicating to the cluster and ensuring the committed offsets are produced into the topic. This means that a consumer is also a producer of sorts. We've covered quite a bit more about offsets, but there are a few more points I want you to add to your growing Kafka encyclopedia, and the offset mode I mentioned a couple of slides back. There are effectively two modes: automatic and manual, automatic being the default. To switch to manual mode, you simply set enable. auto. commit property to false. Of course, by doing this, the property for auto commit interval is irrelevant and therefore ignored. When you do this, you are taking full control of when you want Kafka to consider a record to be fully processed. This is a fairly advanced, but not uncommon scenario. We won't get into it in depth in this course, but I will give you a high level overview of why, how, and what it means to use it. The API for manual offset management consists of two methods: commitSync and commitAsync.
CommitSync and CommitAsync for Manual Offset Management

You would use the commitSync method when you want precise control over when to consider a record truly processed. This is common under circumstances where higher consistency and message processing fidelity is required, where you wouldn't want to retrieve and process new records until you're sure the ones you've currently processed are committed. It is suggested that you invoke this method after you have iterated and processed a batch of consumer records in the for loop, not during. I mean, you can invoke it after every single message, but that level of paranoia may not buy you anything extra other than added latency, because the call is, as the name suggests, synchronous, and will block the thread until it receives a response from the cluster. Hopefully the response is a successful confirmation because if it is an exception, there's not much you can do and you'll just have to start the process of recovery. The good news about commitSync is that it will automatically retry the commit until it succeeds, or again, if it were to receive an unrecoverable error. To control the retry attempt interval, you would work with the retry. back. ms setting, and it's similar to the setting found in the producer configuration as well. The default is 100 ms, so it will retry a lot. With this manual offset management mode, you may be trading throughput and performance for control over the consistency. The synchronous blocking nature of the call can add a measure of latency to the overall polling process. Like the commitSync method, you would use its asynchronous sibling to control when to consider your messages truly processed. The difference here is due to the asynchronous nature of the call, you may not know exactly when the commit succeeded or not. Because of this, the commitAsync method does not automatically retry when a commit doesn't happen. Retrying without knowing whether the first attempt succeeded of failed can lead to ordering issues and possible duplication of records; however, there is a useful option to pass in, and that is a callback. That callback will be triggered upon the commit response from the cluster. With this callback, you can determine the status of the commit and act accordingly. Since this is a non-blocking option, the throughput and overall performance is going to be better because you will not have to wait for a response to continue processing. However, I wouldn't recommend this option unless you register a callback and can handle the responses accordingly, otherwise, you could end up in a worse situation altogether.
When to Manager Your Own Offsets Altogether

So we've nearly completed our journey through our Kafka consumer map. We've discussed at length the important process of managing offsets as part of the overall consumers responsibility for reliably processing messages. The place where offset management occurs is after the poll method has timed out and presented records for processing. Whether this is an auto commit operation happening behind the scenes, or an explicit call to one of the commit APIs, the commit process will take a batch of records, determine their offsets, and ask the consumer coordinator to commit them to the Kafka cluster via the consumer network client, which it does immediately. When the offsets have been confirmed to be committed, the consumer coordinator updates the subscription state object accordingly, so the Fetcher can always know what offsets have bene committed and what next records it should be retrieving. There are a lot of things Kafka can do for you out of the box, but for advanced scenarios, you may need to go outside the box entirely, and leverage Kafka's APIs for complete offset self-management. We discussed many of the facilities for doing this, and I would encourage you to explore the APIs further. The question is: what are some common reasons for taking control of the offsets? As we touched upon already, one of those big reasons is consistency control. Depending on your consumer applications purpose in the larger system, you may need finer grain control over when a message is processed and considered ready to commit. If you leave it to the auto commit behavior, the only determination of done will be when the auto commit interval expires, and that may not be enough to ensure higher levels of consistency. Being able to treat the steps of message consumption and processing as a single atomic operation, that's a good reason. This is commonly understood and known in transaction processing systems as atomicity. It is an important attribute of highly consistent systems, and may be required by your particular system. The main reason independent offset management becomes a common scenario with Kafka is the desire to achieve exactly once semantics of message processing. Because of what can go on within a distributed system like Kafka, there is quite a bit of surface area to get messages out of order or have duplicates. This surface area is largely attributed to the scalable nature of how Kafka handles partitions and automatic partition reassignment and rebalancing; topics which we're going to cover next. But in order to get an exactly once system, you will likely need to manage offsets and the content of the message and/or the result of its processing in the same store where you can have full transactional control of the scope.
Scaling out with Consumer Groups

Up to this point, we've discussed a lot about consumers, mostly single consumers. In these discussions, we've been faced with a scary reality. A single consumer may be required to consume from dozens or possibly hundreds of topics, each with countless partitions. That's a lot for a single anything to manage, let alone having to do it with a single execution thread for both retrieving and processing messages. As I said, it simply isn't realistic to expect a single consumer application to take on the entire burden of message processing from a potentially large Kafka cluster environment. The solution is to be able to scale out the number of consumers consuming messages, but having a bunch of consumers independently consuming messages from topics and partitions won't alone solve this challenge of scalability, they have to work in concert with one another. Throughout this course, we've seen how each component of Apache Kafka has a solution for scaling out. If more message production is needed, the solution is to add more and more producers. If we need more message retention and redundancy, we add more and more brokers. If we need more metadata management facilities, we add more Zookeeper members. But what about scaling the ability to read and process messages beyond a single consumer? Consumer groups is the answer. A consumer group really is a collection of individual, independent consumer processes working together as a team. The only thing required to join a consumer to a consumer group is to use the group. id setting as a configuration property before starting the consumer. When a consumer is part of a consumer group, the task of processing the messages for an entire topic is distributed as evenly as possible amongst the number of consumers. Like any work distribution system, a consumer group can enable higher levels of overall throughput through multiple consumers working in parallel. It can increase the levels of redundancy as the failure or limitation of a single consumer is automatically handled and balanced by Kafka, and with an increased number of working consumers working in parallel, the overall performance can improve as far as the ability to process a large backlog of messages. Let's look at how this works. A consumer group is formed when individual consumers with a common group ID invoke the subscribe method and pass in a common topic list. Behind the scenes, a designated broker is elected to serve as a group coordinator, whose job it is to monitor and maintain a consumer group's membership. In addition, the group coordinator works with the cluster coordinator and Zookeeper to assign and monitor specific partitions within a topic to individual consumers within a consumer group. From the second a consumer group is formed, each consumer is sending regular heartbeats at an interval defined in heartbeat. interval. ms property setting. The group coordinator relies on this heartbeat to determine whether an individual consumer is alive and able to participate in the group. The session. timeout setting is the amount of total time a group coordinator will wait after not receiving any heartbeats before it will consider the consumer failed and take corrective action. The group coordinator's main priority is to ensure that the purpose of the group is being met, and that purpose is sharing the load of a topics messages amongst all of its consumer group members. If there is a consumer that isn't available to share in that load, the group coordinator will remove that consumer and reassign its partitions to another consumer in the group. This is called a consumer rebalance, and it is, as you can imagine, quite a process. If there aren't any additional consumers in the consumer group, the first consumer in the group will get the new assignment, and in this case, end up taking on twice the load to compensate for the failed consumer. When this happens, the first consumer now has to figure out where the failed consumer left off and catch up, hopefully without processing duplicate records. This is why offset management can make or break the Kafka consumers because if it is not handled correctly, the ability for the consumer group to failover and rebalance itself can be compromised. Consider the case if the failed consumer processed messages, but failed to commit them before it failed? The first consumer will likely reprocess the messages because it had no idea what records were actually committed or not. If and when a new consumer joins the group, another rebalance will occur, and the same rebalance protocol will be followed. It's not just a consumer coming in and out of a consumer group that will cause a rebalance, it's also the addition of a new partition. Generally, a consumer group is planned for each application that requires message flow from one or more topics. For example, in this case, we have a consumer group called orders, and it could subscribe to any number of topics related to order management, because the application backend it is intended to server is an order management system.
Consumer Group Coordinator

Let's spend some more time on what happens during a consumer group rebalance, specifically, when a new consumer in the group is assigned a partition that was previously assigned to another consumer. When the new consumer is assigned a partition, in this case, Partition 0, it needs to know what offset it should start from because it does not have a current position for this particular partition. Fortunately, the consumer's subscription state object has cached the last committed offset from the previous consumer, and can now instruct the new consumer that on its first poll on the new partition, that it will start with offset five, since the last committed offset was four. This behavior of determining where the new consumer should reset its offset to is configured in the auto offset resetting setting. Since the default is latest, the new consumer will start reading from the latest known committed position. Of course, this assumes that the committed offset was accurately and completely committed when the previous consumer was rebalanced. If the previous consumer was in the middle of processing records and didn't have the chance to commit its offsets when the rebalance happened, then there could be a chance that when the new consumer picks up, it could be reading from already processed records, thus creating duplicates. To finish up the discussion on consumer groups, let's highlight some of the important duties of the group coordinator without which consumer groups wouldn't be possible. The primary purpose is to make sure each consumer in the consumer group is sharing the partition load across the group. Whenever it can, it will assign one consumer to one partition if there is an equal number of consumers and partitions. However, if there are more consumers in the group than there are partitions, the extra consumers will be idle, creating a consumer over provisioning scenario that the group coordinator can't change unless partitions become available. When a partition does become available, the group coordinator will initiate the rebalancing protocol by engaging each consumer coordinator in the impacted consumers to start the process of rebalancing, so the newly added partition can be assigned to an appropriate consumer. The rebalancing protocol is also initiated during a consumer failure, as we just illustrated.
Demo: Consumer Groups

In this final demo, I will extend the Java-based consumers we've already seen to take on teaming responsibilities within a consumer group. We will have three independent consumers each sharing the same group ID, and each participating in the task of processing messages from a single topic with three partitions. In this simple example, look for how each of the consumers are assigned a partition and are sharing the work of processing messages. Also look for what happens when we add an additional consumer, and when we add an additional partition. Finally, we'll observe what happens when a rebalance is forced. In this demo, we're going to launch three basic consumer applications, which contain identical polling and processing logic. Here it is. It's basically pretty simple. We're just taking the string that's coming through in the producer, and we're taking the value and uppercasing it, and that's it. And each one of these three is identical, and as far as producing, we have a loop running, and we'll produce 99 records of the alphabet in lowercase, and all the processing that it will do on the consumer side is just to turn those into uppercase. So let's get these consumers running. We'll start one by one in each window, and I'll sit there and wait in a polling loop until our producer starts running, and we'll do that right now. Now remember, each of these consumers are in a consumer group, all subscribing to the same topic, and the producer is going to be publishing to that topic. So here we go. First one, the second one, and the third one. So as we can see here, is this particular consumer as part of the consumer group, was getting all of the messages being sent to the first partition, and it took the lowercase alphabet and uppered it. The same thing could be said of the second consumer in the consumer group, it was taking partition 2, taking the value and turning it to uppercase, and then consumer 3 from the consumer group was taking partition 0. Let's take a look at what happens when we add a fourth consumer to the consumer group. Now remember, we have three consumers to the consumer group, and we have one topic with three partitions. We have an overprovisioned consumer group, but let's see what happens. So, we'll start each one of these consumers, let them sit and wait for messages, and then we will produce to them. So now we have four in the consumer group, and we can see it in here, that basically there are four consumers in the consumer group test group, and as I was adding them, they added to them and registered to the group coordinator. So now, let's produce some records. So we see that the first one receives some records, the second one receives some records, the third one did not receive any records, and I believe the fourth one will have received some records. So why didn't the third one receive records? Well, because there's only three consumers in the consumer group, and there's three topics, so one of them is just sitting idle, and that one happened to be the third one. The first one here got partition 1, the second one got partition 2, and the fourth one got partition 0, and they did their job by taking the value and turning it to uppercase all the same. So now that we've added an additional partition, and now we have even numbers of consumers to partitions to consume, let's rerun the producer and see how it now distributes the messages across an even number of partitions, because basically when we added a new partition, it forced a rebalance. So let's see what happens. So for app 1, you've got messages, app 2 got messages, app 3 got messages, and app 4 got messages; 4 got partition 0, 3 got 1, 2 got 3, and 1 got 2. So it did rebalance, it did recognize the new partition, and it did assign the new consumer in the consumer group to that partition. Now that we have an even consumer group, even with the number of partitions, let's force a rebalance. Now, the way you do that is by basically killing a couple of consumers, because if they are no longer present, the group coordinator will not find them, they won't get their heartbeat, and they will remove them from the consumer groups, so let's kill 4 and 3, so now they're sitting there, and let's go back over to here. Now remember, it takes a little while for the rebalance to occur, because basically at this point in time, the group coordinator is waiting around, waiting for some heartbeats from consumer 4 and 3, and so far it's not getting them. And then, after a while it's going to now say, oh, my session's going to start timing out and I'm going to remove the dead consumers from the consumer group. So these consumers are still running, so let's now produce some more records. So now, you'll see that consumer 1 took some records, consumer 2 took some records, and of course, 3 and 4 did not because they were unresponsive, but what happened was 1 and 2 basically were reassigned the partitions that 3 and 4 had, in this case, it was partition 1 and 0 that was reassigned to consumer 1, and 2 and 3 were reassigned to consumer 2.
Configuration and Advanced Topics

We have covered a lot of consumer configuration properties in this module, but we haven't covered all of them due to time and focus. Since the performance and throughput of consumer processing can be affected by various settings and combinations of settings, I thought I would list a few of the more prominent settings here. My goal is to call some of these out so that you can spend some extra time studying them and experimenting with them to understand how the consumer behavior varies. These settings fall into a category I would call performance and overall efficiency. The fetch. min. bytes setting sets as minimum number of bytes that must be returned from the poll. This ensures that you don't have wasted cycles of processing if there aren't enough messages to process. This setting is analogous to the batch size setting on the producer. The max. fetch. wait. ms setting establishes the amount of time to wait if there isn't enough data to meet the threshold set by the fetch. min. bytes setting. This is somewhat analogous to the linger. ms setting in the producer. To ensure that each poll isn't retrieving more data than your processing loop can handle safely, you can set the maximum number of bytes per partition that the poll can retrieve per cycle. Related to this is the setting to establish the maximum number of records allowed per poll cycle. These last two settings are useful to throttle the number and size of each incoming batch of records, should your processing loop be such that a lot of time is spent in processing and you don't want to risk a session timeout. We covered a lot, but there are some things we just weren't able to cover in this introductory course. Each of these fall under the category of taking complete control of the consumer's behavior. You can specify how you want a consumer to read a partitions messages by using the consumer position control API. It comprises of three methods. First is the seek method, allowing you to specify the specific offset you want to read in a given topic and partition. There's also seekToBeginning, which indicates that you want to start from the beginning of a group of a specific topics and partitions. Obviously, seekToEnd is the opposite of seekToBeginning. And then, there's the ability to literally control the flow of messages through pause and resume APIs. These allow you to determine which topics and partitions you may want to pause while focusing on other topics and partitions considered a higher priority. This is useful for situations where a single consumer has to read from multiple different topics and partitions. Finally, there are the rebalance listeners, that you can leverage when subscribing to topics in a consumer group. These listeners will notify you when a rebalance event occurs, so you can manage how you want to handle the offsets yourself.
Summary

Throughout this module, we focused on the internals of a Kafka consumer. We started with a high level map, and started to drill down component by component, and in the process, covered a lot of things, such as the required consumer properties, and their internal consumer representation as the consumer config object, which was analogous to the producer config object in the producer. Once again, how the term message is really a reference to a consumer record, much the same way it was called the producer record from the point of view of the producer in the last module. We talked about how to subscribe to topics and how to assign yourself partitions. We discussed the important differences between the two, and when it may be appropriate to use one over the other. We also talked about the end-to-end consumer polling process, complete with the poll method, the for loop for processing records, and all the internal consumer objects that enable the consumer to function. We also discussed the various different modes and options for managing offsets in the consumer. Additionally, we covered the way Kafka consumers can scale out through consumer groups, and how using consumer groups can increase the overall throughput possible through parallel consumers, but also, the degree in which consumers can be fault-tolerant and robust amidst failure or cluster changes. We covered throughout, the various configuration settings and how they control the behavior and non-functional outcomes of the consumer, and we had some demonstrations showing how to create and operate a Java-based consumer and consumer group. With the core components of Apache Kafka now covered, in this last module, we'll cover the broader ecosystem that Apache Kafka finds itself in, including its current challenges, opportunities, and the most recent areas of continued development and evolution.
Exploring the Kafka Ecosystem and Its Future
Apache Kafka's Success and Challenges

At this point, we've covered the major components of Apache Kafka. I hope you're feeling equipped with enough knowledge to really start exploring and building big data solutions using Kafka. This module is about taking a step back and surveying the landscape in which Apache Kafka exists. We will discuss the success that is enabled, the continued challenges it faces, and how it is evolving to meet those challenges head on. The main use cases for Apache Kafka today have more or less remained the same since it was first created by LinkedIn. It's hard to go anywhere and have discussions about the challenges of data management in modern day enterprises without the mention of Apache Kafka. It is generally regarded as a primary solution for connecting disparate sources of data. With its flexible client APIs, it is possible to write data connectors and syncs for practically any data source. Many of these have been shared and commercialized at this point, and we'll discuss more about them in the coming slides. Apache Kafka is becoming the defacto option for building data supply chains and pipelines that can displace long-standing, expensive, and fragile ETL environments. Within this context, Apache Kafka fits really well with other "Big Data" solutions, like Hadoop and Spark, amongst others, because of its ability to integrate, move, and store data at massive scale. Essentially, reference architectures for data management have started to become established within the industry, and Kafka is a central piece to many of them. However, sometimes new solutions introduce new problems and reinforce old, unsolved problems. Despite the vast utility that Kafka offers today's organizations, there are still a lot of gaps that the industry is being pressured to solve. For example, having the ability to amass and manage more data actually makes it harder to govern data and manage its rapid evolution. The commoditization of technology and business specialization demands lower overhead and less investment. So regardless of how useful something in technology is, it will always be a challenge the more inconsistent or costly it is to wield. Data is becoming more and more of a strategic differentiator. In the last five years, there has been an arms race for anyone and anything that can manage more and more data. The next five years is going to be all about fast data, how to rapidly gain utility from it, particularly in predictive, deep learning contexts. Over the next few slides, I will use these three challenge areas to describe how Kafka is evolving to address these pressures.
Challenges and Solutions for Data Governance

I'll start off with Kafka's challenges with data governance and evolution. Let's consider the common case of a large and growing network of Kafka producers and consumers. As you know by now, each producer is defining its message contract to publish. You'll recall from module four that that contract is based on a fairly rigid type-dependent serialization system. We didn't talk a lot about this or nearly in as much detail as I would've liked, but in advanced cases, it becomes infeasible to restrict message contracts solely based on the built-in serializer types. Eventually, as more data diversity is introduced from different systems, custom serializers come into play. Throughout the message life-cycle, there can be hundreds of different contract versions in motion, with each producer publishing massive amounts of data into Kafka. Of course, it takes consumers to derive any sort of value from the data being produced, but they have to be able to do it by reading the data first, which they are able to do through deserializing the message content. This means that with a growing diversity of producers and the data they're publishing, there is an increased complexity all around because consumers have to work with the data being produced, and the specifications for each type of message it's consuming. The challenge with Kafka in this common scenario is the lack of some common means of cataloging, registering, and reconciling the disparate message specifications and compatibility mappings between the serializing producers and the deserializing consumers. Confluent is one of the biggest Apache Kafka ecosystem contributors, and they have recognized the challenge we just covered. Fortunately, they have started to take steps to address it by introducing the Kafka Schema Registry. This welcome addition to the Kafka family deserves its own course because of the richness of its functionality, but for now, let me introduce how it addresses the challenges we just covered. One of the more universal data serialization formats out there today is called Apache Avro. It was created to address the challenges with disparate data formats and serialization schemes that make integration and interoperability difficult. It is a self-describing version format that is broad industry adoption. With Avro, producers can serialize their messages in an Avro versioned and self-describing format, and expect them to be deserialized seamlessly by the consumers. As the name suggests, the schema used by both producers and consumers can be registered and version managed centrally within the Kafka cluster environment, allowing for easy, restful, service-based discovery, and version compatibility reconciliation. Now, the great thing is the source is fully available on GitHub, and available through the generous Apache version two license.
Challenges and Solutions for Consistency and Productivity

Let's consider a typical enterprise data environment. There are many sources and targets for data. Kafka has made quite a reputation for itself in being the conduit between these sources and targets, but the challenge has been a lot of duplication of effort in terms of writing producer and consumer applications that connect the sources and targets together. The crazy thing is when you think about the work to integrate data stores, they're all more or less the same. I mean, look at relational database management systems for example. They've been around forever, and there's only so many mainstream database vendors out there, yet across the industry, it seems that within every company there's the same duplicated effort to write integrating producers and consumers for those very same data stores. Talk about reinventing the wheel. The same could be said about file systems, NoSQL databases, search engines, and even Hadoop, amongst others not mentioned. The challenge with Kafka in this scenario has been the lack of consistency in providing a common framework for integrating data sources and targets. It was always left to the individual engineers to create their own solutions using the generic producer and consumer client APIs. With each integration effort, there is cost, not only to develop, but to maintain, and that isn't a very efficient or even productive use of time or effort to do something so common. Furthermore, not every company has the resources to develop and maintain these things, which are really becoming commodities at this point. With the 0. 10 release of Apache Kafka, a new framework and marketplace was introduced to address this challenge head on. It's called Kafka Connect and the Connector Hub. As with the case of the Schema Registry, this new innovation deserves its own course to give it justice. The connect framework is an API for developers. It is intended to make the job of connecting data sources and targets easier and more consistent. The goal is to standardize on a common approach for integrating diverse data sources with standard producer and consumer applications. This is awesome because writing highly performant and reliable consumers, for example, can be really hard and complex as we covered in the last module. So having a framework to simplify and standardize this is a huge step forward. Now currently, many of the developers using this framework are those that work for the leading technology data providers, who have started to include a Kafka connector as part of their product roadmaps. Oracle and HP are some noteworthy examples of this. Currently, there are over 50 platform connectors available that are designed to connect to many different products and services, and that list is growing. Confluent itself has created many of these connectors, and they also provide an online portal they call the Connector Hub. They invite anyone and everyone to develop and contribute a Kafka connector using the API and that online portal for distribution. As adoption grows, this is bound to drive more consistency and greater productivity in Kafka-based data integration initiatives. Overall, it's going to get cheaper and faster than ever to get Kafka integrated in enterprises.
Challenges and Solutions for Fast Data

Within the last few years, there has been a lot of hype around predictive analytics, machine learning, real-time, stream-based, whatever buzzword of your choosing. There are multiple technology platforms that all propose to offer a unique ability to deliver upon this hype for real-time or stream-based analytics. Some of these platforms are legitimate viable solutions, such as Apache Storm, Hadoop, Cassandra, and Apache Spark. Again, Kafka is generally found in the middle, but the problem is each one of these technologies introduces a unique and mostly complex model for development and operation. Each have their own API and cluster-based management approach to distributed systems. Kafka itself, as we've covered in this course, has its own API and vast cluster-based model. So, if you have all of these technologies under the same roof, so to speak, that's a tremendous amount of technology to manage and maintain all for the same goal of achieving the ability to process and analyze data in real-time. Touching on the last challenge, this introduces consistency and productivity challenges in integrating it all together. With Kafka generally being positioned between these technologies for integration, it would need an army of producers and consumers to keep the streaming pipes flowing. The challenge here is pretty obvious. Now, I'm not saying all of these different platforms are present in each environment, but many are because they each have their own strengths and advantages that complement the weaknesses of the other, but regardless of whatever these systems come and go, one thing is becoming more consistent, and that is the place Apache Kafka finds itself within these organizations. The 0. 10 release of Apache Kafka was a huge one. In addition to Kafka Connect, a new client library for real-time stream-based processing was introduced. This library is called Kafka Streams. The real value proposition of this is that for organizations that have already made an investment in Apache Kafka, they can now have streaming data capabilities without having to install, run, and maintain all of those different platforms. All they need is their existing Kafka environment. Given everything we've learned about Kafka in this course, I am sure you can see how adding this capability to Kafka wasn't that much of a stress. I mean, consider what Kafka already does with data in motion, and how it does it. This is significant because it doesn't require anything more. I mean, theoretically, Apache Kafka could be the only infrastructure solution required, but in reality, many enterprises have good reason to additionally invest in Apache Hadoop and Spark, so it may be that Kafka itself isn't the only big data system in place, but at the very least, it can be the only system needed for stream-based processing. Regardless, the potential to reduce and consolidate into fewer systems is now a very real possibility. Think of what that can do to lower the initial investment and overall total cost. As I said, Kafka Streams is a client library that works with the Kafka cluster. As you've learned in this course, that's exactly like Kafka producers and consumers, they are client libraries too, and just like we did with the producer and consumer client libraries, Kafka Streams can be embedded within Java-based applications, making the barrier to adopt lower than any other platform offering stream-based processing. Think of it this way. If you already have producers and consumer applications, why not just extend them with the Kafka streams library to provide stream-based processing capabilities all within the same place? This is an exciting area that I hope you'll continue to explore.
Apache Kafka's Ecosystem and Summary

Everything that Kafka is today, and what it will be tomorrow is made possible through the growing and healthy ecosystem of adopters and source code contributors. These are but a few of the big names that not only have based significant parts of their business on Apache Kafka, but also make generous contributions back, allowing all companies and organizations, big and small, to benefit. That's the beauty of the open-source ecosystem in which Apache Kafka is firmly placed. In this module, we covered the undeniable success that Apache Kafka has had since the beginning. It has enabled organizations to solve some of data management's biggest problems, but as I said, in the process, it has introduced new challenges. Many of the challenges facing Kafka and the data management industry in general, stem from the rapidly growing and changing landscape. Data volumes, velocity, and variety are increasing exponentially, and as a significant player in this landscape, Apache Kafka can't rest on its laurels. Luckily, with the vast and supporting ecosystem it has, Kafka has evolved to meet these challenges and establish reinforced foundations upon which to build further for many years to come. We discussed some of these recent innovations, like the Schema Registry, Kafka Connect, and Kafka Streams. I hope you'll agree with me that there is a promising future ahead for Kafka and the many technology professionals and organizations that invest in it. We have come to the end of this course. I hope you learned a lot, at least enough to continue your journey in learning more. It's always hard to decide where to invest your limited amount of time. I personally faced this challenge as the course author in determining what details to focus on and what details to sacrifice, because I wanted you to get the most out of this course within a limited amount of time. I hope I succeeded, but it is hopefully just the beginning for you. I encourage you to continue learning about Apache Kafka, and trying it out. It's a solid bet to make as a technology professional. 